{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge import Rouge\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21370200825834712\n"
     ]
    }
   ],
   "source": [
    "csv_path = '/mnt/workspace/slt_baseline/work_dir/openaslv1_enc_dec_vn/512_pemb_bs48_ep400_encpenc_maskenc_lr3e4_ddp4_dp01_4pt_ccl10m4_e1/test-ep250-valid_valid_eval.csv'\n",
    "with open(csv_path, 'r') as f:\n",
    "    content = f.readlines()\n",
    "    content = [x.split('|') for x in content]\n",
    "hyp = [x[0] for x in content]\n",
    "ref = [x[1] for x in content]\n",
    "\n",
    "rouge=Rouge()\n",
    "scores = rouge.get_scores(hyp, ref, avg=True)\n",
    "print(scores['rouge-l']['f'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2175124854733848\n"
     ]
    }
   ],
   "source": [
    "csv_path = '/mnt/workspace/slt_baseline/work_dir/openaslv1_enc_dec_vn/512_pemb_bs48_ep400_encpenc_maskenc_lr3e4_ddp4_dp01_4pt_ccl10m4_e1/test-ep250-test_test_eval.csv'\n",
    "with open(csv_path, 'r') as f:\n",
    "    content = f.readlines()\n",
    "    content = [x.split('|') for x in content]\n",
    "hyp = [x[0] for x in content]\n",
    "ref = [x[1] for x in content]\n",
    "\n",
    "rouge=Rouge()\n",
    "scores = rouge.get_scores(hyp, ref, avg=True)\n",
    "print(scores['rouge-l']['f'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21629587367368758\n"
     ]
    }
   ],
   "source": [
    "csv_path = '/mnt/workspace/slt_baseline/work_dir/openaslv1_enc_dec_vn/512_pemb_bs48_ep400_encpenc_maskenc_lr3e4_ddp4_dp01_4pt_ccl10m4_abn_e2/test-ep311-valid_valid_eval.csv'\n",
    "\n",
    "with open(csv_path, 'r') as f:\n",
    "    content = f.readlines()\n",
    "    content = [x.split('|') for x in content]\n",
    "hyp = [x[0] for x in content]\n",
    "ref = [x[1] for x in content]\n",
    "\n",
    "rouge=Rouge()\n",
    "scores = rouge.get_scores(hyp, ref, avg=True)\n",
    "print(scores['rouge-l']['f'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21229135144667138\n"
     ]
    }
   ],
   "source": [
    "csv_path = '/mnt/workspace/slt_baseline/work_dir/openaslv1_enc_dec_vn/512_pemb_bs48_ep400_encpenc_maskenc_lr3e4_ddp4_dp01_4pt_ccl10m4_abn_e2/test-ep311-test_test_eval.csv'\n",
    "\n",
    "with open(csv_path, 'r') as f:\n",
    "    content = f.readlines()\n",
    "    content = [x.split('|') for x in content]\n",
    "hyp = [x[0] for x in content]\n",
    "ref = [x[1] for x in content]\n",
    "\n",
    "rouge=Rouge()\n",
    "scores = rouge.get_scores(hyp, ref, avg=True)\n",
    "print(scores['rouge-l']['f'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1893995611017945\n"
     ]
    }
   ],
   "source": [
    "csv_path = '/mnt/workspace/slt_baseline/work_dir/openaslv1_enc_dec_vn/512_pemb_bs48_ep400_maskenc_lr3e4_ddp4_dp01_4pt_fzvb_abl1/test-ep351-test_test_eval.csv'\n",
    "\n",
    "with open(csv_path, 'r') as f:\n",
    "    content = f.readlines()\n",
    "    content = [x.split('|') for x in content]\n",
    "hyp = [x[0] for x in content]\n",
    "ref = [x[1] for x in content]\n",
    "\n",
    "rouge=Rouge()\n",
    "scores = rouge.get_scores(hyp, ref, avg=True)\n",
    "print(scores['rouge-l']['f'])\n",
    "#  add 'the' to biden sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20242570182814912\n"
     ]
    }
   ],
   "source": [
    "csv_path = '/mnt/workspace/slt_baseline/work_dir/openaslv1_enc_dec_vn/512_pemb_bs48_ep400_encpenc_maskenc_lr3e4_ddp4_dp01_4pt_ccl10m4_fzvb_e1/test-ep338-test_test_eval.csv'\n",
    "\n",
    "with open(csv_path, 'r') as f:\n",
    "    content = f.readlines()\n",
    "    content = [x.split('|') for x in content]\n",
    "hyp = [x[0] for x in content]\n",
    "ref = [x[1] for x in content]\n",
    "\n",
    "rouge=Rouge()\n",
    "scores = rouge.get_scores(hyp, ref, avg=True)\n",
    "print(scores['rouge-l']['f'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rouge_l_f1(csv_path):\n",
    "    with open(csv_path, 'r') as f:\n",
    "        content = f.readlines()\n",
    "        content = [x.split('|') for x in content]\n",
    "    hyp = [x[0] for x in content]\n",
    "    ref = [x[1] for x in content]\n",
    "\n",
    "    rouge=Rouge()\n",
    "    scores = rouge.get_scores(hyp, ref, avg=True)\n",
    "    print(scores['rouge-l']['f'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20483777724867286\n"
     ]
    }
   ],
   "source": [
    "csv_path = '/mnt/workspace/slt_baseline/work_dir/openaslv1_enc_dec_vn/512_pemb_bs48_ep400_maskenc_lr3e4_ddp4_dp01_4pt_ccl10m4_abl1/test-ep368-test_test_eval.csv'\n",
    "rouge_l_f1(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20920890956130578\n"
     ]
    }
   ],
   "source": [
    "csv_path = '/mnt/workspace/slt_baseline/work_dir/openaslv1_enc_dec_vn/512_pemb_bs48_ep400_encpenc_maskenc_lr3e4_ddp4_dp01_4pt_abl1/test-ep393-test_test_eval.csv'\n",
    "rouge_l_f1(csv_path)\n",
    "# the |in oregon it is also illegal to lure wild animals by leaving behind food or garbage.\n",
    "# a |the tentacles are called \"filopodia.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reading checkpoint /mnt/workspace/bleurt/bleurt/BLEURT-20.\n",
      "INFO:tensorflow:Config file found, reading.\n",
      "INFO:tensorflow:Will load checkpoint BLEURT-20\n",
      "INFO:tensorflow:Loads full paths and checks that files exists.\n",
      "INFO:tensorflow:... name:BLEURT-20\n",
      "INFO:tensorflow:... bert_config_file:bert_config.json\n",
      "INFO:tensorflow:... max_seq_length:512\n",
      "INFO:tensorflow:... vocab_file:None\n",
      "INFO:tensorflow:... do_lower_case:None\n",
      "INFO:tensorflow:... sp_model:sent_piece\n",
      "INFO:tensorflow:... dynamic_seq_length:True\n",
      "INFO:tensorflow:Creating BLEURT scorer.\n",
      "INFO:tensorflow:Creating SentencePiece tokenizer.\n",
      "INFO:tensorflow:Creating SentencePiece tokenizer.\n",
      "INFO:tensorflow:Will load model: /mnt/workspace/bleurt/bleurt/BLEURT-20/sent_piece.model.\n",
      "INFO:tensorflow:SentencePiece tokenizer created.\n",
      "INFO:tensorflow:Creating Eager Mode predictor.\n",
      "INFO:tensorflow:Loading model.\n",
      "INFO:tensorflow:BLEURT initialized.\n",
      "0.3675444491954969\n"
     ]
    }
   ],
   "source": [
    "from bleurt import score\n",
    "\n",
    "checkpoint = \"/mnt/workspace/bleurt/bleurt/BLEURT-20\"\n",
    "csv_path = '/mnt/workspace/slt_baseline/work_dir/openaslv1_enc_dec_vn/512_pemb_bs48_ep400_encpenc_maskenc_lr3e4_ddp4_dp01_4pt_ccl10m4_e1/test-ep250-valid_valid_eval.csv'\n",
    "with open(csv_path, 'r') as f:\n",
    "    content = f.readlines()\n",
    "    content = [x.split('|') for x in content]\n",
    "hyp = [x[0] for x in content]\n",
    "ref = [x[1] for x in content]\n",
    "\n",
    "scorer = score.BleurtScorer(checkpoint)\n",
    "scores = scorer.score(references=ref, candidates=hyp)\n",
    "# assert isinstance(scores, list) and len(scores) == 1\n",
    "print(sum(scores)/len(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reading checkpoint /mnt/workspace/bleurt/bleurt/BLEURT-20.\n",
      "INFO:tensorflow:Config file found, reading.\n",
      "INFO:tensorflow:Will load checkpoint BLEURT-20\n",
      "INFO:tensorflow:Loads full paths and checks that files exists.\n",
      "INFO:tensorflow:... name:BLEURT-20\n",
      "INFO:tensorflow:... bert_config_file:bert_config.json\n",
      "INFO:tensorflow:... max_seq_length:512\n",
      "INFO:tensorflow:... vocab_file:None\n",
      "INFO:tensorflow:... do_lower_case:None\n",
      "INFO:tensorflow:... sp_model:sent_piece\n",
      "INFO:tensorflow:... dynamic_seq_length:True\n",
      "INFO:tensorflow:Creating BLEURT scorer.\n",
      "INFO:tensorflow:Creating SentencePiece tokenizer.\n",
      "INFO:tensorflow:Creating SentencePiece tokenizer.\n",
      "INFO:tensorflow:Will load model: /mnt/workspace/bleurt/bleurt/BLEURT-20/sent_piece.model.\n",
      "INFO:tensorflow:SentencePiece tokenizer created.\n",
      "INFO:tensorflow:Creating Eager Mode predictor.\n",
      "INFO:tensorflow:Loading model.\n",
      "INFO:tensorflow:BLEURT initialized.\n",
      "0.36351552025629924\n"
     ]
    }
   ],
   "source": [
    "checkpoint = \"/mnt/workspace/bleurt/bleurt/BLEURT-20\"\n",
    "csv_path = '/mnt/workspace/slt_baseline/work_dir/openaslv1_enc_dec_vn/512_pemb_bs48_ep400_encpenc_maskenc_lr3e4_ddp4_dp01_4pt_ccl10m4_e1/test-ep250-test_test_eval.csv'\n",
    "with open(csv_path, 'r') as f:\n",
    "    content = f.readlines()\n",
    "    content = [x.split('|') for x in content]\n",
    "hyp = [x[0] for x in content]\n",
    "ref = [x[1] for x in content]\n",
    "\n",
    "scorer = score.BleurtScorer(checkpoint)\n",
    "scores = scorer.score(references=ref, candidates=hyp)\n",
    "# assert isinstance(scores, list) and len(scores) == 1\n",
    "print(sum(scores)/len(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reading checkpoint /mnt/workspace/bleurt/bleurt/BLEURT-20.\n",
      "INFO:tensorflow:Config file found, reading.\n",
      "INFO:tensorflow:Will load checkpoint BLEURT-20\n",
      "INFO:tensorflow:Loads full paths and checks that files exists.\n",
      "INFO:tensorflow:... name:BLEURT-20\n",
      "INFO:tensorflow:... bert_config_file:bert_config.json\n",
      "INFO:tensorflow:... max_seq_length:512\n",
      "INFO:tensorflow:... vocab_file:None\n",
      "INFO:tensorflow:... do_lower_case:None\n",
      "INFO:tensorflow:... sp_model:sent_piece\n",
      "INFO:tensorflow:... dynamic_seq_length:True\n",
      "INFO:tensorflow:Creating BLEURT scorer.\n",
      "INFO:tensorflow:Creating SentencePiece tokenizer.\n",
      "INFO:tensorflow:Creating SentencePiece tokenizer.\n",
      "INFO:tensorflow:Will load model: /mnt/workspace/bleurt/bleurt/BLEURT-20/sent_piece.model.\n",
      "INFO:tensorflow:SentencePiece tokenizer created.\n",
      "INFO:tensorflow:Creating Eager Mode predictor.\n",
      "INFO:tensorflow:Loading model.\n",
      "INFO:tensorflow:BLEURT initialized.\n",
      "0.37300369835380687\n"
     ]
    }
   ],
   "source": [
    "checkpoint = \"/mnt/workspace/bleurt/bleurt/BLEURT-20\"\n",
    "csv_path = '/mnt/workspace/slt_baseline/work_dir/openaslv1_enc_dec_vn/512_pemb_bs48_ep400_encpenc_maskenc_lr3e4_ddp4_dp01_4pt_ccl10m4_abn_e2/test-ep311-valid_valid_eval.csv'\n",
    "with open(csv_path, 'r') as f:\n",
    "    content = f.readlines()\n",
    "    content = [x.split('|') for x in content]\n",
    "hyp = [x[0] for x in content]\n",
    "ref = [x[1] for x in content]\n",
    "\n",
    "scorer = score.BleurtScorer(checkpoint)\n",
    "scores = scorer.score(references=ref, candidates=hyp)\n",
    "# assert isinstance(scores, list) and len(scores) == 1\n",
    "print(sum(scores)/len(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reading checkpoint /mnt/workspace/bleurt/bleurt/BLEURT-20.\n",
      "INFO:tensorflow:Config file found, reading.\n",
      "INFO:tensorflow:Will load checkpoint BLEURT-20\n",
      "INFO:tensorflow:Loads full paths and checks that files exists.\n",
      "INFO:tensorflow:... name:BLEURT-20\n",
      "INFO:tensorflow:... bert_config_file:bert_config.json\n",
      "INFO:tensorflow:... max_seq_length:512\n",
      "INFO:tensorflow:... vocab_file:None\n",
      "INFO:tensorflow:... do_lower_case:None\n",
      "INFO:tensorflow:... sp_model:sent_piece\n",
      "INFO:tensorflow:... dynamic_seq_length:True\n",
      "INFO:tensorflow:Creating BLEURT scorer.\n",
      "INFO:tensorflow:Creating SentencePiece tokenizer.\n",
      "INFO:tensorflow:Creating SentencePiece tokenizer.\n",
      "INFO:tensorflow:Will load model: /mnt/workspace/bleurt/bleurt/BLEURT-20/sent_piece.model.\n",
      "INFO:tensorflow:SentencePiece tokenizer created.\n",
      "INFO:tensorflow:Creating Eager Mode predictor.\n",
      "INFO:tensorflow:Loading model.\n",
      "INFO:tensorflow:BLEURT initialized.\n",
      "0.3668023273501484\n"
     ]
    }
   ],
   "source": [
    "checkpoint = \"/mnt/workspace/bleurt/bleurt/BLEURT-20\"\n",
    "csv_path = '/mnt/workspace/slt_baseline/work_dir/openaslv1_enc_dec_vn/512_pemb_bs48_ep400_encpenc_maskenc_lr3e4_ddp4_dp01_4pt_ccl10m4_abn_e2/test-ep311-test_test_eval.csv'\n",
    "with open(csv_path, 'r') as f:\n",
    "    content = f.readlines()\n",
    "    content = [x.split('|') for x in content]\n",
    "hyp = [x[0] for x in content]\n",
    "ref = [x[1] for x in content]\n",
    "\n",
    "scorer = score.BleurtScorer(checkpoint)\n",
    "scores = scorer.score(references=ref, candidates=hyp)\n",
    "# assert isinstance(scores, list) and len(scores) == 1\n",
    "print(sum(scores)/len(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20964552852729215\n"
     ]
    }
   ],
   "source": [
    "csv_path = '/mnt/workspace/slt_baseline/work_dir/openaslv1_enc_dec_vn/512_pemb_bs48_ep400_encpenc_maskenc_lr3e4_ddp4_dp01_4pt_ccl10m2_abv_e2/test-ep218-test_test_eval.csv'\n",
    "rouge_l_f1(csv_path)\n",
    "# are |i was born and raised in dominican republic and moved to new york at 9 years old."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20852974413009362\n"
     ]
    }
   ],
   "source": [
    "csv_path = '/mnt/workspace/slt_baseline/work_dir/openaslv1_enc_dec_vn/512_pemb_bs48_ep400_encpenc_maskenc_lr3e4_ddp4_dp01_4pt_ccl10m4_abvna_e1/test-ep276-test_test_eval.csv'\n",
    "rouge_l_f1(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reading checkpoint /mnt/workspace/bleurt/bleurt/BLEURT-20.\n",
      "INFO:tensorflow:Config file found, reading.\n",
      "INFO:tensorflow:Will load checkpoint BLEURT-20\n",
      "INFO:tensorflow:Loads full paths and checks that files exists.\n",
      "INFO:tensorflow:... name:BLEURT-20\n",
      "INFO:tensorflow:... bert_config_file:bert_config.json\n",
      "INFO:tensorflow:... max_seq_length:512\n",
      "INFO:tensorflow:... vocab_file:None\n",
      "INFO:tensorflow:... do_lower_case:None\n",
      "INFO:tensorflow:... sp_model:sent_piece\n",
      "INFO:tensorflow:... dynamic_seq_length:True\n",
      "INFO:tensorflow:Creating BLEURT scorer.\n",
      "INFO:tensorflow:Creating SentencePiece tokenizer.\n",
      "INFO:tensorflow:Creating SentencePiece tokenizer.\n",
      "INFO:tensorflow:Will load model: /mnt/workspace/bleurt/bleurt/BLEURT-20/sent_piece.model.\n",
      "INFO:tensorflow:SentencePiece tokenizer created.\n",
      "INFO:tensorflow:Creating Eager Mode predictor.\n",
      "INFO:tensorflow:Loading model.\n",
      "INFO:tensorflow:BLEURT initialized.\n",
      "0.34345068858142513\n"
     ]
    }
   ],
   "source": [
    "from bleurt import score\n",
    "\n",
    "checkpoint = \"/mnt/workspace/bleurt/bleurt/BLEURT-20\"\n",
    "csv_path = '/mnt/workspace/slt_baseline/work_dir/openaslv1_enc_dec_vn/512_pemb_bs48_ep400_maskenc_lr3e4_ddp4_dp01_4pt_fzvb_abl1/test-ep351-test_test_eval.csv'\n",
    "with open(csv_path, 'r') as f:\n",
    "    content = f.readlines()\n",
    "    content = [x.split('|') for x in content]\n",
    "hyp = [x[0] for x in content]\n",
    "ref = [x[1] for x in content]\n",
    "\n",
    "scorer = score.BleurtScorer(checkpoint)\n",
    "scores = scorer.score(references=ref, candidates=hyp)\n",
    "# assert isinstance(scores, list) and len(scores) == 1\n",
    "print(sum(scores)/len(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35385938004789047\n"
     ]
    }
   ],
   "source": [
    "csv_path = '/mnt/workspace/slt_baseline/work_dir/openaslv1_enc_dec_vn/512_pemb_bs48_ep400_encpenc_maskenc_lr3e4_ddp4_dp01_4pt_ccl10m4_fzvb_e1/test-ep338-test_test_eval.csv'\n",
    "with open(csv_path, 'r') as f:\n",
    "    content = f.readlines()\n",
    "    content = [x.split('|') for x in content]\n",
    "hyp = [x[0] for x in content]\n",
    "ref = [x[1] for x in content]\n",
    "\n",
    "scores = scorer.score(references=ref, candidates=hyp)\n",
    "# assert isinstance(scores, list) and len(scores) == 1\n",
    "print(sum(scores)/len(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3564607442402449\n"
     ]
    }
   ],
   "source": [
    "csv_path = '/mnt/workspace/slt_baseline/work_dir/openaslv1_enc_dec_vn/512_pemb_bs48_ep400_encpenc_maskenc_lr3e4_ddp4_dp01_4pt_abl1/test-ep393-test_test_eval.csv'\n",
    "with open(csv_path, 'r') as f:\n",
    "    content = f.readlines()\n",
    "    content = [x.split('|') for x in content]\n",
    "hyp = [x[0] for x in content]\n",
    "ref = [x[1] for x in content]\n",
    "\n",
    "scores = scorer.score(references=ref, candidates=hyp)\n",
    "# assert isinstance(scores, list) and len(scores) == 1\n",
    "print(sum(scores)/len(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35957138228123303\n"
     ]
    }
   ],
   "source": [
    "csv_path = '/mnt/workspace/slt_baseline/work_dir/openaslv1_enc_dec_vn/512_pemb_bs48_ep400_maskenc_lr3e4_ddp4_dp01_4pt_ccl10m4_abl1/test-ep368-test_test_eval.csv'\n",
    "with open(csv_path, 'r') as f:\n",
    "    content = f.readlines()\n",
    "    content = [x.split('|') for x in content]\n",
    "hyp = [x[0] for x in content]\n",
    "ref = [x[1] for x in content]\n",
    "\n",
    "scores = scorer.score(references=ref, candidates=hyp)\n",
    "# assert isinstance(scores, list) and len(scores) == 1\n",
    "print(sum(scores)/len(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3649824794885687\n"
     ]
    }
   ],
   "source": [
    "csv_path = '/mnt/workspace/slt_baseline/work_dir/openaslv1_enc_dec_vn/512_pemb_bs48_ep400_encpenc_maskenc_lr3e4_ddp4_dp01_4pt_ccl10m2_abv_e2/test-ep218-test_test_eval.csv'\n",
    "with open(csv_path, 'r') as f:\n",
    "    content = f.readlines()\n",
    "    content = [x.split('|') for x in content]\n",
    "hyp = [x[0] for x in content]\n",
    "ref = [x[1] for x in content]\n",
    "\n",
    "scores = scorer.score(references=ref, candidates=hyp)\n",
    "# assert isinstance(scores, list) and len(scores) == 1\n",
    "print(sum(scores)/len(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35896627849242724\n"
     ]
    }
   ],
   "source": [
    "csv_path = '/mnt/workspace/slt_baseline/work_dir/openaslv1_enc_dec_vn/512_pemb_bs48_ep400_encpenc_maskenc_lr3e4_ddp4_dp01_4pt_ccl10m4_abvna_e1/test-ep276-test_test_eval.csv'\n",
    "with open(csv_path, 'r') as f:\n",
    "    content = f.readlines()\n",
    "    content = [x.split('|') for x in content]\n",
    "hyp = [x[0] for x in content]\n",
    "ref = [x[1] for x in content]\n",
    "\n",
    "scores = scorer.score(references=ref, candidates=hyp)\n",
    "# assert isinstance(scores, list) and len(scores) == 1\n",
    "print(sum(scores)/len(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bleurt import score\n",
    "\n",
    "checkpoint = \"/mnt/workspace/bleurt/bleurt/BLEURT-20\"\n",
    "csv_path = '/mnt/workspace/slt_baseline/work_dir/openaslv1_enc_dec_vn/512_pemb_bs48_ep400_maskenc_lr3e4_ddp4_dp01_4pt_fzvb_abl1/test-ep351-test_test_eval.csv'\n",
    "with open(csv_path, 'r') as f:\n",
    "    content = f.readlines()\n",
    "    content = [x.split('|') for x in content]\n",
    "hyp = [x[0] for x in content]\n",
    "ref = [x[1] for x in content]\n",
    "\n",
    "scorer = score.BleurtScorer(checkpoint)\n",
    "scores = scorer.score(references=ref, candidates=hyp)\n",
    "# assert isinstance(scores, list) and len(scores) == 1\n",
    "print(sum(scores)/len(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.15 ('slt')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1a5ee8f268a58a1501ad7aef09cde53105f57cea18e29cd62af7d0e62261f331"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
